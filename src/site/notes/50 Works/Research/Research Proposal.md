---
{"dg-publish":true,"permalink":"/50-works/research/research-proposal/","title":"Research Proposal","created":"2024-04-27","updated":"2024-09-13"}
---


## ABSTRACT

## LIST OF TABLES

## LIST OF FIGURES

## LIST OF ACRONYMS

- CS: Computer Science
- PCR: Peer Code Review
- GBL: Games-based Learning
- SDT: Self-Determination Theory
- IMI: Intrinsic Motivation Inventory
- CRT: Code Review Taxonomy

## CHAPTER 1: PROBLEM STATEMENT


<div class="transclusion internal-embed is-loaded"><a class="markdown-embed-link" href="/50-works/research/problem-statement/" aria-label="Open link"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a><div class="markdown-embed">





PCR is a fundamental part of being a professional software developer [@li2006 9]. This is a process that is done when a developer makes a change or add to the already existing codebase. One or more of their teammates will evaluate and make suggestions on the code based on an agreed upon style guide and general coding best practices. These suggestions include, but are not limited to, variable and function naming conventions, spacing, comments, size and scope of functions. The developer then has to implement the feedback from their peers, often creating a dialogue with the team that leads to uncovering more related issues with the codebase. This process is critical in the quality assurance of the application and is commonly enacted by most software companies. Despite this requirement, the research suggests that students lack motivation to give quality peer feedback during the code review process [@indriasari2021a]. To give quality peer feedback, students must be engaged in the process. The literature states that students learn better by doing than by passively listening [@powell2009] and that students can deepen their own learning through peer assessment [@race2001].

However, despite its numerous benefits, one of the challenges encountered in current PCR practices is the low motivation among CS students in providing quality peer feedback. This lack of motivation can hinder the effectiveness of the PCR process and prevent students from fully reaping the benefits of this collaborative learning experience [@petersen2018]. This can be due to various reasons such as time constraints, lack of incentive, or inadequate understanding of the value of constructive feedback. Additionally, students may feel uncomfortable critiquing their peers' work or may not have the necessary skills to provide meaningful and constructive feedback [@perez-quinones2009].

Another challenge is the potential for biases and conflicts to arise during PCR. Students may struggle to separate personal relationships from professional feedback, leading to tension within the peer group. Furthermore, differences in skill levels and experiences among students can also impact the effectiveness of the PCR process, as it may be difficult for students to provide feedback on code that is significantly more advanced or complex than their own [@indriasari2021].

Lastly, the logistics of organizing and managing PCR sessions can also pose challenges. Coordinating schedules, ensuring equal participation, and providing clear guidelines for the review process can be demanding for educators and may impact the overall quality of the review experience [@indriasari2023].

Addressing these challenges is crucial to enhancing the effectiveness of PCR and maximizing its benefits for CS students. Implementing strategies to motivate students, providing training on giving and receiving constructive feedback, and fostering an inclusive and supportive peer review environment are essential steps towards overcoming these obstacles.


</div></div>


## CHAPTER 2: CONCEPTUAL FRAMEWORK


<div class="transclusion internal-embed is-loaded"><a class="markdown-embed-link" href="/50-works/research/conceptual-framework/" aria-label="Open link"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a><div class="markdown-embed">





Providing effective code review feedback is a crucial skill for CS students as they prepare to enter the workforce [@sadowski2018]. From my experience as a professional software developer in the industry, I know that PCR is a fundamental skill for programmers. From my experience as a CS student, I know that traditional academic approaches do not always engage or motivate learners especially for the PCR process. On the other end, as a CS teacher, I have seen firsthand how disengaged students can be during PCR sessions. Providing superficial feedback benefits neither the reviewer nor the reviewee. I want to help create a classroom environment where feedback is constructive and where students feel empowered as part of the development process. It is important to create an environment where feedback is constructive and empowers students as part of the development process [@hattie2007]. This is particularly crucial for developing essential skills in professional software developers, such as giving effective feedback during PCR.

This lack of motivation frequently results in surface-level feedback that does little to improve code quality or foster deep learning [@ramsden2003]. This disengagement poses a significant challenge for educators aiming to maximize the effectiveness of PCR practices. The root of this issue may be motivational. SDT provides a potential lens for understanding this phenomenon by highlighting the importance of competence, autonomy, and relatedness for intrinsic motivation [@deci1994]. Traditional PCR processes may fail to adequately support these needs: _competence_, where students may doubt their ability to provide valuable feedback or feel that the focus is solely on error-finding or quality-assurance testing; _autonomy_, where limited choices in how to engage with PCR (code to review, feedback format, etc.) may stifle student ownership; and _relatedness_, where a lack of community focus or a shared sense of purpose can diminish the feeling that PCR is a collaborative improvement process.

GBL offers a promising approach to address these motivational barriers hindering effective PCR. GBL prioritizes immersion, challenge, and (sometimes) social interaction [@papastergiou2009]. These elements have the potential to: _enhance competence_, where well-designed challenges and in-game rewards can build confidence as coding proficiency increases; _foster autonomy_, where GBL systems can offer choices within a structured learning experience, increasing student agency; and _promote relatedness_, where narrative and collaborative gameplay can make PCR feel more purposeful and community-oriented.

As an avid player of both digital and analogue games, I find that my experience in gaming also influences my interest in this topic. In the world of gaming, especially in multiplayer games, communication and teamwork are crucial for success. Similarly, in the area of PCR, effective communication and collaboration are essential for producing high-quality code. Furthermore, the problem-solving and critical thinking skills honed through gaming also translate to the world of programming and code review. The analytical mindset and attention to detail required in gaming parallel the skills needed for thorough code review [@schmitz2011]. Understanding how to engage and motivate students in the context of PCR aligns with the principles of game design, where creating an engaging and immersive experience is paramount. I believe my experience playing games provides me with a unique perspective on the dynamics of PCR and motivates me to delve deeper into this topic.

In this study, I want to examine the quality of PCR feedback and GBL through the lens of student motivation and SDT. Observing the influence of GBL on the quality of feedback provided during PCR will be the key focus of this research. By harnessing the potential of GBL to transform PCR into a more intrinsically motivating, and subsequently, more valuable learning experience, my ultimate goal is to develop GBL interventions that increase student engagement, leading to higher-quality feedback that benefits everyone involved.


</div></div>


## CHAPTER 3: LITERATURE REVIEW


<div class="transclusion internal-embed is-loaded"><a class="markdown-embed-link" href="/50-works/research/literature-review/" aria-label="Open link"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a><div class="markdown-embed">

<div class="markdown-embed-title">

# Literature Review

</div>




## 3.1 The Importance of PCR

PCR is a cornerstone of software development, both as a vital industry practice and as a valuable learning tool within CS education. By critically examining their peers' code, students hone their analytical skills, deepen their understanding of coding principles, and develop essential communication and collaboration abilities. However, the effectiveness of PCR hinges on student motivation. Research indicates that many CS students lack the intrinsic drive to provide meaningful and constructive feedback. This undermines the potential benefits of PCR for all participants. Motivational theories, particularly SDT, provide a lens for understanding the factors that influence student engagement with PCR. SDT posits that intrinsic motivation flourishes when individuals experience a sense of competence, autonomy, and relatedness. Applying SDT to the context of PCR can help identify specific aspects of the process that might either support or undermine student motivation, and subsequently, the quality of the feedback they provide. Emerging research suggests that gamification–the integration of game-like elements into non-game settings–can improve participation, motivation, and feedback quality in peer review. However, the potential of GBL, which centers on full-fledged games for educational aims, remains unexplored within this context. GBL prioritizes intrinsic motivation through immersive gameplay, potentially fostering the deep engagement necessary for providing thoughtful PCRs. This literature review examines the motivational challenges inherent in the PCR process and investigates the potential of GBL to address them. By synthesizing existing research on gamification, motivational theories, and the use of games in CS education, this review seeks to illuminate a significant research gap: the absence of studies specifically exploring GBL as a strategy to enhance student motivation and the quality of feedback provided during PCR within Computer Science education.

PCR plays a crucial role in CS education. By examining and providing feedback on their peers' code, students sharpen their understanding of coding standards, best practices, and software design principles [@cross1987; @indriasari2020a]. PCR not only reinforces technical skills but also fosters collaborative learning and critical thinking. Moreover, engaging in PCR helps students develop the ability to communicate effectively with their peers and learn from each other's mistakes [@indriasari2020a; @petersen2018]. In addition, PCR simulates real-world scenarios where software developers often work in teams and collaborate on projects. By honing their skills in giving and receiving constructive feedback, students prepare themselves for the professional environment they will enter upon graduation. This practice also contributes to a more thorough understanding of different programming languages, problem-solving techniques, and industry-specific tools and technologies [@indriasari2020a; @perez-quinones2009].

Engaging in PCR also helps students in developing their analytical skills and attention to detail, which are essential for identifying and fixing bugs and errors in code. Additionally, it encourages students to think critically about alternative solutions and approaches, thereby broadening their problem-solving capabilities [@li2006; @petersen2018]. PCR also serves as a valuable tool for self-improvement. By analyzing and evaluating their classmates' code, students can identify areas for personal growth and enhancement of their own coding practices. This process of critically assessing others' code compels students to reflect on their own solutions and consider alternative approaches [@hamer2009; @hundhausen2013]. Furthermore, PCR hopes to promote a culture of accountability and responsibility among students. The intention is that if individuals know that their work will be scrutinized by their peers, they will be motivated to produce high-quality and well-documented code. This looks to foster a sense of ownership and pride in their work, leading to a more professional approach to software development. PCR is integral to the development of not only technical expertise but also crucial soft skills that are essential for success in any technology-related career [@hamer2009; @indriasari2020a].

## 3.2 The Motivational Challenge

Motivating CS students to engage in quality PCR presents specific challenges. Studies reveal that student-generated peer reviews often lack depth and specificity, described as short and non-committal, failing to meet the expectations for useful feedback [@indriasari2020]. This indicates a need for strategies that enhance student engagement in the peer review process, ensuring that the feedback is not only frequent but also meaningful and constructive. Addressing these challenges is crucial for improving the learning outcomes in programming courses, where PCR is an essential component [@indriasari2021].

SDT is a motivational framework that emphasizes three core psychological needs: competence, autonomy, and relatedness. These needs play a crucial role in driving intrinsic motivation, leading to greater engagement and improved performance in learning contexts [@deci1994]. Competence refers to the need to feel effective in one's interactions with the environment. In the context of peer feedback in CS education, students are more likely to be motivated to provide constructive feedback when they feel competent in their ability to understand and evaluate their peers' code [@bandura2012; @indriasari2020]. Autonomy pertains to the need for individuals to feel a sense of choice and volition in their actions. When students have the autonomy to express their opinions and insights during PCR, it fosters a greater sense of ownership and motivation [@pintrich2003; @indriasari2021a]. Relatedness encompasses the desire to feel connected to others and experience a sense of belonging. In the context of peer feedback, creating a supportive and collaborative environment where students can engage in constructive discussions fosters a sense of relatedness, thereby enhancing their motivation to actively participate in the review process [@powell2009; @indriasari2023]. Understanding and addressing these core psychological needs outlined in SDT can significantly influence the effectiveness of peer feedback in CS education. By recognizing the importance of competence, autonomy, and relatedness, educators can implement strategies to foster a more engaging and motivating PCR environment for students.

## 3.3 Gamification vs. Game-Based Learning

Two learning approaches prevalent in the literature about increasing student motivation are gamification and GBL. These two approaches seek to increase student motivation by incorporating elements of games into instructional strategies. Simply put, gamification involves the use of game elements in non-game contexts, while GBL involves the use of actual games to deliver educational content. Therefore, while gamification relies on extrinsic motivators like rewards and recognition, GBL emphasizes intrinsic motivators such as enjoyment and engagement with the game and its educational content.

Gamification involves integrating game design elements, such as points, badges, and leaderboards, into non-game contexts to enhance engagement and motivation. It does not necessarily involve playing a game, but rather the use of game elements to make an activity more game-like and engaging [@jayasinghe2013]. In gamification, extrinsic motivation is often employed through the use of external rewards such as points, badges, or leaderboards to encourage desired behaviours or actions. This type of motivation comes from outside the individual and is not inherently related to the activity itself [@goshevski2017; @llorens-largo2016; @oktaviati2018]. Gamification has been shown to have a significant impact on student motivation and engagement in CS education. Research studies indicate that incorporating game elements into the learning process can enhance students' enthusiasm for the subject matter and increase their willingness to participate in activities such as PCR [@indriasari2023]. Integrating gamification into PCR can be achieved through various strategies. One effective approach is the use of gamified peer review platforms, where students can earn points, badges, or other rewards for providing high-quality and constructive feedback to their peers. Additionally, the incorporation of game elements such as challenges, levels, and collaborative problem-solving tasks can make the peer review process more engaging and enjoyable for CS students [@indriasari2021]. By integrating gamified learning strategies, educators can create an environment that promotes active involvement and extrinsic motivation among students, thus leading to an improved ability for compute science students' to PCR [@indriasari2020].

Conversely, GBL refers to using games to deliver specific educational content. This can include digital games, board games, or other types of games designed for educational purposes. GBL directly involves playing a game as part of the learning process [@al-azawi2016], and typically focuses on intrinsic motivation, which arises from the activity itself. In this approach, the engagement and enjoyment derived from playing the game are directly linked to the learning process. The challenge, curiosity, and enjoyment inherent in the game itself motivate the learners [@goshevski2017; @papastergiou2009]. GBL applications in CS education are diverse and designed to engage students in various aspects of the field. For instance, in CS, games are utilized to teach algorithms, data structures, networks, software testing, and programming languages [@schmitz2011; @videnovik2023]. This approach allows students to not only learn complex concepts in an interactive and fun way but also fosters critical thinking and collaboration skills. One of the key benefits is the bridging of the gap between theory and practice, enabling students to apply their knowledge in real-world contexts [@chiang2011; @jayasinghe2013]. Furthermore, leveraging storytelling and narrative elements within a game-based peer review structure can create a more immersive and incentivizing experience for the participants. This approach allows students to not only learn complex concepts in an interactive and fun way but also fosters critical thinking and collaboration skills [@al-azawi2016; @papastergiou2009]. The impact of GBL on student motivation and engagement in CS education is substantial. Studies have shown that incorporating GBL approaches not only increases students' motivation but also promotes active engagement in the learning process [@lopez-fernandez2021]. By leveraging the immersive and interactive nature of games, educators can create a more dynamic and stimulating learning environment for CS students [@videnovik2023].

## 3.4 The Potential of Game-Based Learning

A substantial body of research exists regarding the use of gamification within CS education [@mohamedmasrop2019]. This indicates that the integration of game-like elements such as points, badges, and leaderboards has been well explored in various CS learning contexts. However, there's a notable disparity when it comes to GBL, especially when focusing on its applications in the field of CS. This suggests a potential underutilization of full-fledged games in promoting CS learning objectives. While PCR offers undeniable benefits for developing essential coding, analytical, and communication skills, its success is contingent on student motivation. SDT provides a valuable framework for analyzing how elements of the PCR process could impact students' feelings of competence, autonomy, and relatedness, ultimately influencing their engagement and the quality of the feedback they provide. Existing research demonstrates the potential of gamification to enhance aspects of peer review, but its reliance on extrinsic motivators may have limitations for fostering the sustained intrinsic motivation required for giving comprehensive feedback. GBL, with its emphasis on enjoyment, immersion, and challenge, offers a promising yet under-investigated approach to addressing the motivational challenges within CS PCR. The literature reveals that gamification has been investigated within the realm of PCR to enhance the feedback process. This shows a greater emphasis on gamified approaches compared to utilizing games with deeper narratives and mechanics for peer assessment purposes. Whereas the intersection of gamification and PCR appears to be a small area of focus, the intersection of GBL and PCR is smaller still, if non-existent. The lack of studies investigated the potential of GBL for improving PCR within CS education represents a significant gap in the current research landscape. This leaves room for further exploration of how GBL could be designed effectively within the unique context of PCR.

This review, while by no means exhaustive, seeks to highlight a significant research gap: the absence of studies specifically examining the use of GBL to improve student motivation and feedback quality within CS PCR. This research project aims to address this gap by exploring if the application of GBL would have a direct impact on the quality of feedback given during PCR. Research in this area has the potential to significantly improve the overall effectiveness of PCR as a learning tool within CS education, ultimately better preparing students for success in their future professional careers.


</div></div>


## CHAPTER 4: METHODOLOGY


<div class="transclusion internal-embed is-loaded"><a class="markdown-embed-link" href="/50-works/research/methodology/" aria-label="Open link"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a><div class="markdown-embed">





This project is grounded in the existing literature on PCR, the application of motivational theories (specifically SDT) to education, and the use of GBL in CS. It will contribute to the field by exploring a novel approach to a persistent challenge in CS education–how to cultivate the student motivation essential for effective PCR and the development of crucial software development skills.

## 4.1 Research Questions

1. Does a game-based learning intervention increase the quality of feedback provided during CS PCR?
2. Does the game-based learning intervention influence students' perceived competence, autonomy, and relatedness, as conceptualized by SDT?

## 4.2 Research Design

This study will employ a quantitative quasi-experimental design. A two-group post-test design will allow for the investigation of how a GBL intervention influences both the quality of feedback provided during CS PCR and students' self-reported motivation in alignment with SDT.

## 4.3 Target population

The target population is third-year CS students at the CEGEP level in Quebec. This population is selected due to their advanced programming experience and the critical role of PCR in preparing them for collaborative software development practices. The study will be conducted within two sections of an advanced programming course in the CS program at John Abbott College, with a sample population of approximately 30-45 students.

## 4.4 Procedure

At the beginning of the Fall 2024 semester, the students will be informed that their teacher is conducting a research project about PCR. They will be notified that around week 10, all students (approximately 30-45) will engage in a PCR exercise during their regular class time. Participants will be in one of two groups. Group A students will engage in PCR after playing a game specifically designed to employ code review concepts and methods. Alternatively, the game will be unrelated to code review, but prime the cognitive abilities to provide quality feedback. For this reason, The rules and logistics of the game for group A are yet to be determined. Group B students will use the traditional PCR method currently employed in the course. Both groups will use the PCR rubric (Appendix A). Immediately following the PCR exercise, both groups will complete the Intrinsic Motivation Inventory (IMI) [@ryan1983] (Appendix D).

## 4.5 Instruments

The IMI is a validated Likert-style survey which measures student motivation in the context of PCR, including sub-scales for competence, autonomy, relatedness, and enjoyment. It uses a 7-point scale where 1 is "not at all true" and 7 is "very true". The questions will be rephrased slightly contextualizing the PCR experience. Examples are:

1. I think peer code review is an important activity.
2. I think I am pretty good at peer code review.

A Code Review Taxonomy [@hamer2015; @indriasari2023] (Appendix B) will designate comments within categories such as "positive", "negative", "advice/action", as well as the specificity of these comments (general or code-specific).

## 4.6 Data Analysis

T-tests or ANOVA will be used to compare mean scores on IMI sub-scales between the game-based and non-game-based groups. This will assess differences in motivational outcomes as a result of the type of PCR approach. Frequency counts will be generated for each type of feedback provided by both groups using the code review taxonomy. Chi-square tests will be used to compare the prevalence of different feedback types between the two groups.

## 4.7 Ethical Considerations

The researcher's dual role as an instructor and researcher presents potential for coercion, thus the researcher will not be present during the data collection phase if this is seen as problematic. If so, The facilitator will be a colleague from the JAC Computer Science program or the research supervisor. Explicitly informed consent (Appendix C) and measures to protect student confidentiality and grades are crucial, so all student data will be anonymized by the intervention facilitator to reduce the researcher's bias. Student will be informed that they can opt-out at any point even after the data is collected. All students will be given the GBL experience after the data collection phase to ensure equity of treatment. The data will be collected through either a Moodle or Microsoft form. In either case, the anonymized data will be held on Canadian servers.

## 4.8 Timeline

Data will be collected around week 7-8 of the Fall 2024 semester in my Game Programming course. The collection process will last between 1.5-3 hours during a period of one class. After the data is collected, the data will be analyzed in the latter half of the Fall 2024 semester into the Winter 2025 semester. The final paper will be finalized in Winter 2025 and submitted in Spring 2025. The results will be shared during MEC953.


</div></div>


## CHAPTER 5: CLOSING STATEMENT

## Appendix A: PCR RUBRIC

==Replace with clean code rubric==

## Appendix B: CODE REVIEW TAXONOMY


<div class="transclusion internal-embed is-loaded"><a class="markdown-embed-link" href="/50-works/research/code-review-taxonomy/" aria-label="Open link"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a><div class="markdown-embed">

<div class="markdown-embed-title">

# Code Review Taxonomy

</div>




- **S+**: Comments in this category provided positive feedback about a speciﬁc element of the code.
- **S−**: Comments in this category provided speciﬁc negative feedback about the functionality, style or correctness of the program.
- **S0**: Comments in this category were speciﬁc, but were not obviously positive or negative in tone.
- **SA**: Comments in this category provided speciﬁc advice to a student about how to improve their code.
- **G+**: Comments in this category are general comments that are positive. The comments do not relate to a speciﬁc element of style or requirement speciﬁed in the assignment.
- **G−**: Comments in this category are general negative comments. They do not refer to any speciﬁc elements of code, but are instead comments directed at the overall quality (summary comments).
- **G0**: Comments in this category are general comments that do not have either positive or negative connotations.
- **GA**: Comments in this category provided general advice to peers, but did not refer to speciﬁcs within the code.
- **PV**: Comments in this category were personal in tone in that they recognised that the comments, although being about a submission, were directed to another person. Many of these were combined with one of the other categories, linked with a general or speciﬁc criticism.
- **OT**: Comments in this category were off-topic.


</div></div>


## Appendix C: CONSENT FORM


<div class="transclusion internal-embed is-loaded"><a class="markdown-embed-link" href="/50-works/research/code-review-taxonomy/" aria-label="Open link"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a><div class="markdown-embed">

<div class="markdown-embed-title">

# Code Review Taxonomy

</div>




- **S+**: Comments in this category provided positive feedback about a speciﬁc element of the code.
- **S−**: Comments in this category provided speciﬁc negative feedback about the functionality, style or correctness of the program.
- **S0**: Comments in this category were speciﬁc, but were not obviously positive or negative in tone.
- **SA**: Comments in this category provided speciﬁc advice to a student about how to improve their code.
- **G+**: Comments in this category are general comments that are positive. The comments do not relate to a speciﬁc element of style or requirement speciﬁed in the assignment.
- **G−**: Comments in this category are general negative comments. They do not refer to any speciﬁc elements of code, but are instead comments directed at the overall quality (summary comments).
- **G0**: Comments in this category are general comments that do not have either positive or negative connotations.
- **GA**: Comments in this category provided general advice to peers, but did not refer to speciﬁcs within the code.
- **PV**: Comments in this category were personal in tone in that they recognised that the comments, although being about a submission, were directed to another person. Many of these were combined with one of the other categories, linked with a general or speciﬁc criticism.
- **OT**: Comments in this category were off-topic.


</div></div>



<div class="transclusion internal-embed is-loaded"><a class="markdown-embed-link" href="/50-works/research/consent-form/" aria-label="Open link"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a><div class="markdown-embed">





## Purpose

This project is being conducted by Vikram Singh, a Computer Science Teacher at John Abbott College, for the completion of a Master’s Degree in College Teaching, accredited by the Université de Sherbrooke. This study explores how different approaches to peer code review affect student motivation and feedback quality.

## Procedure

Depending on your section, you will be in one of two groups:

- **Group A:** You'll play a short game related to code review concepts, followed by a peer code review activity.
- **Group B:** You'll participate in a standard peer code review activity.

Regardless of your group, you'll complete a survey about your experience and your feedback will be analyzed along with the contents of the feedback you gave your peer.

## Potential Risks

There are no known risks for participation in this study.

## Potential Benefits

By investigating what makes peer code review motivating (or not), your participation could lead to the design of interventions that make peer code review a more engaging and beneficial process for everyone. Your participation could help students develop stronger feedback skills, crucial for both their success in CS courses and future careers. The findings could provide valuable information to your instructor and others about how to refine peer code review practices, potentially leading to widespread changes that enhance the learning experience for many CS students. For your interest, the results of the study will be sent to you after the study has been completed, if so desired.

## Confidentiality

Your participation in this study is confidential in the following ways:

1. Your name will not appear in the research results.
2. The researcher/teacher will never know if you agree or do not agree to participate in this study, therefore the choice to participate or not has no impact on your final grade, nor on any future interaction with your teacher. The supervisor will randomly select students from those who do accept and the names will be removed from the student work which is used for data collection.
3. The feedback comments and survey results will be anonymous and kept for five years in Microsoft OneDrive behind two-factor authentication.
4. The Microsoft Forms questionnaire will be completed anonymously and your personal information will not be revealed. The servers for Microsoft Forms and OneDrive are stored in Canada and therefore your data is protected by Canadian laws.

## Right to Withdraw

Your participation in this research is completely voluntary. You have the right to not participate or withdraw without the teacher’s knowledge at any time by contacting the research supervisor, Paul Darvasi, at [paul.darvasi@usherbrooke.ca](mailto:paul.darvasi@usherbrooke.ca).

## Questions

If you have any questions about the content or methods of this study, please feel free to contact the teacher/researcher, Vikram Singh, at [vikram.singh@johnabbott.qc.ca](mailto:vikram.singh@johnabbott.qc.ca) or the supervisor, Paul Darvasi, at [paul.darvasi@usherbrooke.ca](mailto:paul.darvasi@usherbrooke.ca).

If you have any questions about your rights or treatment during this study, please contact the Research and Innovation Officer at JAC, Teresa Hackett, at [teresa.hackett@johnabbott.qc.ca](mailto:teresa.hackett@johnabbott.qc.ca).

## Statement of Consent

I attest that I have read the above information and that I freely consent to participate in the study about the peer code review in the context of my 420-5P6 Game Programming course during the Fall 2024 semester.

- Student Name (please print):
- Student Number:
- Student Signature:
- Date:
- I wish to receive the results of the study. My email is:


</div></div>


## Appendix D: INTRINSIC MOTIVATION INVENTORY


<div class="transclusion internal-embed is-loaded"><a class="markdown-embed-link" href="/50-works/research/intrinsic-motivation-inventory/" aria-label="Open link"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a><div class="markdown-embed">





## Scale Description

The Intrinsic Motivation Inventory (IMI) is a multidimensional measurement device intended to assess participants' subjective experience related to a target activity in laboratory experiments. It has been used in several experiments related to intrinsic motivation and self-regulation (e.g., Ryan, 1982; Ryan, Mims & Koestner, 1983; Plant & Ryan, 1985; Ryan, Connell, & Plant, 1990; Ryan, Koestner & Deci, 1991; Deci, Eghrari, Patrick, & Leone, 1994). The instrument assesses participants' interest/enjoyment, perceived competence, effort, value/usefulness, felt pressure and tension, and perceived choice while performing a given activity, thus yielding six subscale scores. Recently, a seventh subscale has been added to tap the experiences of relatedness, although the validity of this subscale has yet to be established. The **interest/enjoyment subscale is considered the self-report measure of intrinsic motivation**; thus, although the overall questionnaire is called the Intrinsic Motivation Inventory, it is only the one subscale that assesses intrinsic motivation, per se. As a result, the interest/enjoyment subscale often has more items on it that do the other subscales. The perceived choice and perceived competence concepts are theorized to be positive predictors of both self-report and behavioral measures of intrinsic motivation, and pressure/tension is theorized to be a negative predictor of intrinsic motivation. Effort is a separate variable that is relevant to some motivation questions, so is used it its relevant. The value/usefulness subscale is used in internalization studies (e.g., Deci et al, 1994), the idea being that people internalize and become self-regulating with respect to activities that they experience as useful or valuable for themselves. Finally, the relatedness subscale is used in studies having to do with interpersonal interactions, friendship formation, and so on.

The IMI consists of varied numbers of items from these subscales, all of which have been shown to be factor analytically coherent and stable across a variety of tasks, conditions, and settings. The general criteria for inclusion of items on subscales have been a factor loading of at least 0.6 on the appropriate subscale, and no cross loadings above 0.4. Typically, loadings substantially exceed these criteria. Nonetheless, we recommend that investigators perform their own factor analyses on new data sets. Past research suggests that order effects of item presentation appear to be negligible, and the inclusion or exclusion of specific subscales appears to have no impact on the others. Thus, it is rare that all items have been used in a particular experiment. Instead, experimenters have chosen the subscales that are relevant to the issues they are exploring.

The IMI items have often been modified slightly to fit specific activities. Thus, for example, an item such as "I tried very hard to do well at this activity" can be changed to "I tried very hard to do well on these puzzles" or "...in learning this material" without effecting its reliability or validity. As one can readily tell, there is nothing subtle about these items; they are quite face-valid. However, in part, because of their straightforward nature, caution is needed in interpretation. We have found, for example, that correlations between self-reports of effort or interest and behavioral indices of these dimensions are quite modest--often around 0.4. Like other self-report measures, there is always the need to appropriately interpret how and why participants report as they do. Egoinvolvements, self-presentation styles, reactance, and other psychological dynamics must be considered. For example, in a study by Ryan, Koestner, and Deci (1991), we found that when participants were ego involved, the engaged in pressured persistence during a free choice period and this behavior did not correlate with the self-reports of interest/enjoyment. In fact, we concluded that to be confident in one's assessment of intrinsic motivation, one needs to find that the free-choice behavior and the self-reports of interest/enjoyment are significantly correlated.

Another issue is that of redundancy. Items within the subscales overlap considerably, although randomizing their presentation makes this less salient to most participants. Nonetheless, shorter versions have been used and been found to be quite reliable. The incremental R for every item above 4 for any given factor is quite small.

Still, it is very important to recognize that multiple item subscales consistently outperform single items for obvious reasons, and they have better external validity.

On The Scale page, there are five sections. First, the full 45 items that make up the 7 subscales are shown, along with information on constructing your own IMI and scoring it. Then, there are four specific versions of the IMI that have been used in past studies. This should give you a sense of the different ways it has been used. These have different numbers of items and different numbers of subscales, and they concern different activities. First, there is a standard, 22-item version that has been used in several studies, with four subscales: interest/ enjoyment, perceived competence, perceived choice, and pressure/tension. Second, there is a short 9-item version concerned with the activity of reading some text material; it has three subscales: interest/enjoyment, perceived competence, and pressure/tension. Then, there is the 25-item version that was used in the internalization study, including the three subscales of value/usefulness, interest/enjoyment, and perceived choice. Finally, there is a 29-item version of the interpersonal relatedness questionnaire that has five subscales: relatedness, interest/enjoyment, perceived choice, pressure/tension, and effort.

Finally, McAuley, Duncan, and Tammen (1987) did a study to examine the validity of the IMI and found strong support for its validity.

### References

Deci, E. L., Eghrari, H., Patrick, B. C., & Leone, D. (1994). Facilitating internalization: The selfdetermination theory perspective. _Journal of Personality_, _62_, 119-142.

McAuley, E., Duncan, T., & Tammen, V. V. (1987). Psychometric properties of the Intrinsic Motivation Inventory in a competitive sport setting: A confirmatory factor analysis. _Research Quarterly for Exercise and Sport, 60,_ 48-58.

Plant, R. W., & Ryan, R. M. (1985). Intrinsic motivation and the effects of self-consciousness, selfawareness, and ego-involvement: An investigation of internally-controlling styles. _Journal of Personality_, _53_, 435-449.

Ryan, R. M. (1982). Control and information in the intrapersonal sphere: An extension of cognitive evaluation theory. _Journal of Personality and Social Psychology_, _43_, 450-461.

Ryan, R. M., Connell, J. P., & Plant, R. W. (1990). Emotions in non-directed text learning. _Learning and Individual Differences_, _2_, 1-17.

Ryan, R. M., Koestner, R., & Deci, E. L. (1991). Varied forms of persistence: When free-choice behavior is not intrinsically motivated. _Motivation and Emotion_, _15_, 185-205.

Ryan, R. M., Mims, V., & Koestner, R. (1983). Relation of reward contingency and interpersonal context to intrinsic motivation: A review and test using cognitive evaluation theory. _Journal of Personality and Social Psychology_, _45_, 736-750.

## The Scales

THE POST-EXPERIMENTAL INTRINSIC MOTIVATION INVENTORY

(Below are listed all 45 items that can be used depending on which are needed.)

For each of the following statements, please indicate how true it is for you, using the following scale:

```
         1    2    3    4    5    6    7
not at all true | somewhat true | very true
```

### Interest/Enjoyment

- I enjoyed doing this activity very much.
- This activity was fun to do.
- I thought this was a boring activity. (R)
- This activity did not hold my attention at all. (R)
- I would describe this activity as very interesting. I thought this activity was quite enjoyable.
- While I was doing this activity, I was thinking about how much I enjoyed it.

### Perceived Competence

- I think I am pretty good at this activity.
- I think I did pretty well at this activity, compared to other students. After working at this activity for awhile, I felt pretty competent.
- I am satisfied with my performance at this task. I was pretty skilled at this activity.
- This was an activity that I couldn't do very well. (R)

### Effort/Importance

- I put a lot of effort into this.
- I didn't try very hard to do well at this activity. (R)
- I tried very hard on this activity.
- It was important to me to do well at this task. I didn't put much energy into this. (R)

### Pressure/Tension

- I did not feel nervous at all while doing this. (R)
- I felt very tense while doing this activity.
- I was very relaxed in doing these. (R)
- I was anxious while working on this task.
- I felt pressured while doing these.

### Perceived Choice

- I believe I had some choice about doing this activity.
- I felt like it was not my own choice to do this task. (R)
- I didn't really have a choice about doing this task. (R)
- I felt like I had to do this. (R)
- I did this activity because I had no choice. (R)
- I did this activity because I wanted to.
- I did this activity because I had to. (R)

### Value/Usefulness

- I believe this activity could be of some value to me.
- I think that doing this activity is useful for _blank_.
- I think this is important to do because it can _blank_.
- I would be willing to do this again because it has some value to me.
- I think doing this activity could help me to _blank_.
- I believe doing this activity could be beneficial to me.
- I think this is an important activity.

### Relatedness

- I felt really distant to this person. (R)
- I really doubt that this person and I would ever be friends. (R)
- I felt like I could really trust this person.
- I'd like a chance to interact with this person more often.
- I'd really prefer not to interact with this person in the future. (R)
- I don't feel like I could really trust person. (R)
- It is likely that this person and I could become friends if we interacted a lot.
- I feel close to this person.

**Constructing the IMI for your study.** First, decide which of the variables (factors) you want to use, based on what theoretical questions you are addressing. Then, use the items from those factors, randomly ordered. If you use the value/usefulness items, you will need to complete the three items as appropriate. In other words, if you were studying whether the person believes an activity is useful for improving concentration, or becoming a better basketball player, or whatever, then fill in the blanks with that information. If you do not want to refer to a particular outcome, then just truncate the items with its being useful, helpful, or important.

**Scoring information for the IMI.** To score this instrument, you must first reverse score the items for which an (R) is shown after them. To do that, subtract the item response from 8, and use the resulting number as the item score. Then, calculate subscale scores by averaging across all of the items on that subscale. The subscale scores are then used in the analyses of relevant questions.

---

The following is a 22 item version of the scale that has been used in some lab studies on intrinsic motivation. It has four subscales: interest/enjoyment, perceived choice, perceived competence, and pressure/tension. The interest/enjoyment subscale is considered the self-report measure of intrinsic motivation; perceived choice and perceived competence are theorized to be positive predictors of both self-report and behavioral measures of intrinsic motivation. Pressure tension is theorized to be a negative predictor of intrinsic motivation. Scoring information is presented after the questionnaire itself.

## TASK EVALUATION QUESTIONNAIRE

For each of the following statements, please indicate how true it is for you, using the following scale:

```
         1    2    3    4    5    6    7
not at all true | somewhat true | very true
```

1. While I was working on the task I was thinking about how much I enjoyed it.
2. I did not feel at all nervous about doing the task.
3. I felt that it was my choice to do the task.
4. I think I am pretty good at this task.
5. I found the task very interesting.
6. I felt tense while doing the task.
7. I think I did pretty well at this activity, compared to other students.
8. Doing the task was fun.
9. I felt relaxed while doing the task.
10. I enjoyed doing the task very much.
11. I didn't really have a choice about doing the task.
12. I am satisfied with my performance at this task.
13. I was anxious while doing the task.
14. I thought the task was very boring.
15. I felt like I was doing what I wanted to do while I was working on the task.
16. I felt pretty skilled at this task.
17. I thought the task was very interesting.
18. I felt pressured while doing the task.
19. I felt like I had to do the task.
20. I would describe the task as very enjoyable.
21. I did the task because I had no choice.
22. After working at this task for awhile, I felt pretty competent.

**Scoring information**. Begin by reverse scoring items # 2, 9, 11, 14, 19, 21. In other words, subtract the item response from 8, and use the result as the item score for that item. This way, a higher score will indicate more of the concept described in the subscale name. Thus, a higher score on pressure/tension means the person felt more pressured and tense; a higher score on perceived competence means the person felt more competent; and so on. Then calculate subscale scores by averaging the items scores for the items on each subscale. They are as follows. The (R) after an item number is just a reminder that the item score is the reverse of the participant's response on that item.

- Interest/enjoyment: 1, 5, 8, 10, 14 (R), 17, 20
- Perceived competence: 4, 7, 12, 16, 22
- Perceived choice: 3, 11 (R), 15, 19 (R), 21 (R)
- Pressure/tension: 2 (R), 6, 9 (R), 13, 18

The subscale scores can then be used as dependent variables, predictors, or mediators, depending on the research questions being addressed.

---

### TEXT MATERIAL QUESTIONNAIRE I

For each of the following statements, please indicate how true it is for your, using the following scale as a guide:

```
         1    2    3    4    5    6    7
not at all true | somewhat true | very true
```

1. While I was reading this material, I was thinking about how much I enjoyed it.
2. I did not feel at all nervous while reading.
3. This material did not hold my attention at all.
4. I think I understood this material pretty well.
5. I would describe this material as very interesting.
6. I think I understood this material very well, compared to other students.
7. I enjoyed reading this material very much.
8. I felt very tense while reading this material.
9. This material was fun to read.

**Scoring information**. Begin by reverse scoring items # 2 and 3. In other words, subtract the item response from 8, and use the result as the item score for that item. This way, a higher score will indicate more of the

concept described in the subscale name. Then calculate subscale scores by averaging the items scores for the items on each subscale. They are shown below. The (R) after an item number is just a reminder that the item score is the reverse of the participant's response on that item.

- Interest/enjoyment: 1, 3 (R), 5, 7, 9
- Perceived competence: 4, 6
    Pressure/tension: 2 (R), 8

---

The next version of the questionnaire was used for a study of internalization with an uninteresting computer task (Deci et al., 1994).

### ACTIVITY PERCEPTION QUESTIONNAIRE

The following items concern your experience with the task. Please answer all items. For each item, please indicate how true the statement is for you, using the following scale as a guide:

```
         1    2    3    4    5    6    7
not at all true | somewhat true | very true
```

1. I believe that doing this activity could be of some value for me.
2. I believe I had some choice about doing this activity.
3. While I was doing this activity, I was thinking about how much I enjoyed it.
4. I believe that doing this activity is useful for improved concentration.
5. This activity was fun to do.
6. I think this activity is important for my improvement.
7. I enjoyed doing this activity very much.
8. I really did not have a choice about doing this activity.
9. I did this activity because I wanted to.
10. I think this is an important activity.
11. I felt like I was enjoying the activity while I was doing it.
12. I thought this was a very boring activity.
13. It is possible that this activity could improve my studying habits.
14. I felt like I had no choice but to do this activity.
15. I thought this was a very interesting activity.
16. I am willing to do this activity again because I think it is somewhat useful.
17. I would describe this activity as very enjoyable.
18. I felt like I had to do this activity.
19. I believe doing this activity could be somewhat beneficial for me.
20. I did this activity because I had to.
21. I believe doing this activity could help me do better in school.
22. While doing this activity I felt like I had a choice.
23. I would describe this activity as very fun.
24. I felt like it was not my own choice to do this activity.
25. I would be willing to do this activity again because it has some value for me.

**Scoring information**. Begin by reverse scoring items # 8, 12, 14, 18, 20, and 24 by subtracting the item response from 8 and using the result as the item score for that item. Then calculate subscale scores by averaging the items scores for the items on each subscale. They are shown below. The (R) after an item number is just a reminder that the item score is the reverse of the participant's response on that item.

- Interest/enjoyment: 3, 5, 7, 11, 12 (R), 15, 17, 23
- Value/usefulness: 1, 4, 6, 10, 13, 16, 19, 21, 25
- Perceived choice: 2, 8 (R), 9, 14 (R), 18 (R), 20 (R), 22, 24 (R)

---

### SUBJECT IMPRESSIONS QUESTIONNAIRE

The following sentences describe thoughts and feelings you may have had regarding the other person who participated in the experiment with you. For each of the following statement please indicate how true it is for you, using the following scale as a guide:

```
         1    2    3    4    5    6    7
not at all true | somewhat true | very true
```

1. While I was interacting with this person, I was thinking about how much I enjoyed it.
2. I felt really distant to this person.
3. I did not feel at all nervous about interacting with this person.
4. I felt like I had choice about interacting with this person.
5. I would describe interacting with this person as very enjoyable.
6. I really doubt that this person and I would ever become friends.
7. I found this person very interesting.
8. I enjoyed interacting with this person very much.
9. I felt tense while interacting with this person.
10. I really feel like I could trust this person.
11. Interacting with this person was fun.
12. I felt relaxed while interacting with this person.
13. I'd like a chance to interact more with this person.
14. I didn't really have a choice about interacting with this person.
15. I tried hard to have a good interaction with this person.
16. I'd really prefer not to interact with this person in the future.
17. I was anxious while interacting with this person.
18. I thought this person was very boring.
19. I felt like I was doing what I wanted to do while I was interacting with this person.
20. I tried very hard while interacting with this person.
21. I don't feel like I could really trust this person.
22. I thought interacting with this person was very interesting.
23. I felt pressured while interacting with this person.
24. I think it's likely that this person and I could become friends.
25. I felt like I had to interact with this person.
26. I feel really close to this person.
27. I didn't put much energy into interacting with this person.
28. I interacted with this person because I had no choice.
29. I put some effort into interacting with this person.

**Scoring information**. Begin by reverse scoring items # 2, 3, 6, 12, 14, 16, 18, 21, 25, 27, and 28 by subtracting the item response from 8 and using the result as the item score for that item. Then calculate subscale scores by averaging the items scores for the items on each subscale. They are shown below. The (R) after an item number is just a reminder that the item score is the reverse of the participant's response on that item.

- Relatedness: 2 (R), 6 (R), 10, 13, 16 (R), 21 (R), 24, 26
- Interest/enjoyment: 1, 5, 7, 8, 11, 18 (R), 22
- Perceived choice: 4, 14 (R), 19, 25 (R), 28 (R)
- Pressure/tension: 3 (R), 9, 12 (R), 17, 23
- Effort: 15, 20, 27 (R), 29


</div></div>


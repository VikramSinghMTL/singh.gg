---
{"title":"Results","created":"2025-02-17","modified":"2025-03-08","dg-publish":true,"permalink":"/50-works/research/results/","dgPassFrontmatter":true,"updated":"2025-03-08"}
---


## Pre-Test Findings

Before evaluating the impact of the game-based learning intervention, a pre-test was conducted to assess participants' gaming preferences, prior exposure to game-based learning, and familiarity with card-based mechanics. The majority of students reported a strong preference for games, with a mean of 4.64 (on a 5-point scale) for the statement "I enjoy playing games (analogue or digital)." Nearly all participants (93%, $N=42$) enjoyed playing video games, with 74% playing at least once a week. Board games (67%) and card games (62%) were also popular.

Despite this enthusiasm for gaming, prior exposure to game-based learning in academic settings was limited. Only 5% of participants reported frequent exposure, while 57% had rarely engaged in such learning activities, and 42% had never participated in game-based learning. Given that the intervention used a card-based peer feedback game, familiarity with card games was also assessed, with 95% of students indicating at least some familiarity.

When it came to gameplay preferences, 64% of students preferred playing with others, 26% had no preference, and only 10% preferred playing alone. Competitive games were slightly more popular, with 52% favouring them, while 28% had no preference, and 20% preferred cooperative experiences.

## Peer Feedback Quality

Descriptive statistics for feedback quality scores ($N=37$) are presented in Table 2. Each student provided three separate peer feedback scores which were analyzed using a Code Review Taxonomy (Appendix B) and assigned a numerical score based on predefined criteria (see Table 1 in Methodology). These scores ranged from 0 (off-topic/irrelevant feedback) to 5 (strong actionable feedback).

**Table 2**

_Descriptive Statistics for Feedback Quality_

|                    | Pre-Test | Post-Test |
| ------------------ | -------- | --------- |
| Mean               | 2.95     | 3.84      |
| Median             | 3        | 4         |
| Mode               | 2        | 4         |
| Standard Deviation | 1.25     | 1.14      |

The median feedback quality score was 2.95 (pre) and 3.84 (post), indicating an upward shift in feedback ratings.

A visual representation of the distribution of pre and post-intervention feedback quality scores is shown in Figure X. As depicted in the box plot, post-test feedback scores demonstrated an increase in median values.

**Figure 2**

_Pre and Post-Intervention Peer Feedback Scores_

![Results-1.png](/img/user/00%20System/Assets/Results-1.png)

A Wilcoxon signed-rank test was conducted to assess whether the median feedback quality scores significantly increased after the intervention. The results indicated that post-intervention feedback scores ($Mdn=4.0$) were significantly higher than pre-intervention scores ($Mdn=3.0$), $z=-3.09, p<.05$.

## Motivation Sub-Scales

Descriptive statistics for feedback quality scores are presented in Table 3.

**Table 3**

_Descriptive Statistics for Motivation Scores_

|                    | Autonomy Pre | Autonomy Post | Competence Pre | Competence Post | Relatedness Pre | Relatedness Post |
| ------------------ | ------------ | ------------- | -------------- | --------------- | --------------- | ---------------- |
| Mean               | 3.39         | 3.78          | 3.52           | 3.61            | 3.29            | 3.67             |
| Median             | 3.67         | 3.67          | 3.50           | 3.67            | 3.50            | 4.00             |
| Mode               | 3.67         | 3.33          | 3.33           | 3.67            | 3.50            | 4.00             |
| Standard Deviation | 0.72         | 0.69          | 0.76           | 0.76            | 0.86            | 0.93             |

Mean scores for autonomy, competence, and relatedness increased from pre-test to post-test, though the extent of these changes varied.

Figure 3 presents box plots comparing pre and post-test scores for autonomy, competence, and relatedness.

**Figure 3**

_Pre and Post-Test Scores for Autonomy, Competence, and Relatedness_

![Results-2.png](/img/user/00%20System/Assets/Results-2.png)

The distributions indicate that while autonomy showed a noticeable increase, changes in competence and relatedness were less pronounced.

A series of independent t-tests, as seen in Table X, were conducted to examine differences in perceived autonomy, competence, and relatedness before and after the game-based learning intervention.

**Table 4**

_Independent T-Test Results for SDT Sub-Scales_

| Sub-Scale   | Pre-Test Mean (SD) | Post-Test Mean (SD) | t(79) | p (two-tail) |
| ----------- | ------------------ | ------------------- | ----- | ------------ |
| Autonomy    | 3.39 (0.72)        | 3.78 (0.69)         | -2.46 | 0.016        |
| Competence  | 3.52 (0.76)        | 3.61 (0.76)         | -0.54 | 0.592        |
| Relatedness | 3.29 (0.86)        | 3.67 (0.93)         | -1.92 | 0.058        |

The results indicate a statistically significant increase in autonomy at the $Î±=0.05$ threshold, with post-test scores ($M=3.78, SD=0.69$) being significantly higher than pre-test scores ($M=3.39, SD=0.72$), $t(79)=-2.46, p=.016$, suggesting that the intervention positively influenced students' sense of autonomy. However, no significant differences were found in competence, where post-test scores ($M=3.61, SD=0.76$) did not significantly differ from pre-test scores ($M=3.52, SD=0.76$), $t(79)=-0.54, p=.592$. Similarly, relatedness showed a marginal increase, but the difference did not reach statistical significance, with post-test scores ($M=3.67, SD=0.93$) compared to pre-test scores ($M=3.29, SD=0.86$), $t(79)=-1.92, p=.058$. These findings suggest that while the intervention had a measurable effect on students' perceived autonomy, its impact on competence and relatedness was not statistically significant.

## Post-Test Findings

As a secondary measure of the intervention's effectiveness, students were asked to rate their enjoyment of the peer feedback card game. The results indicate a high level of engagement, with a mean of 4.79 (on a 5-point scale) and a median and mode of 5, suggesting that most students strongly agreed that they enjoyed playing the game.

Students also provided open-ended responses to the following question: _"Did participating in the card game influence your approach to giving or receiving peer feedback? Please describe any specific ways the game affected your motivation, engagement, or quality of feedback, or if it had no impact."_ A thematic analysis revealed four primary themes: increased motivation due to game mechanics, no significant change in feedback approach, awareness of feedback impact but not strong motivation, and perceived pressure or lack of understanding. The distribution of responses is summarized in Table 5.

**Table 5**

_Thematic Breakdown of Student Feedback_

| Theme                                                   | Number of Responses (N=39) |
| ------------------------------------------------------- | -------------------------- |
| Increased motivation due to game mechanics              | 21                         |
| No significant change in feedback approach              | 8                          |
| Awareness of feedback impact but not strongly motivated | 6                          |
| Perceived pressure or lack of understanding             | 4                          |

Over half of the students (54%) reported that the game-based intervention increased their motivation to provide better feedback. Many described the incentive structure as a driving force behind their engagement, with one student stating, _"100%, before I only put 'good job' or 'error in x.js,' but now I went in-depth knowing it would give me an edge while playing the game."_ Another noted, _"It simply motivated me to look at their code further and give more insightful feedback."_ Many students noted increased motivation, as evidenced by their detailed responses.

Despite this, 21% of students reported that the game had no meaningful effect on their approach to peer feedback. Some explained that they were already motivated to provide detailed responses and did not feel the game altered their process. One student reflected, _"Not necessarily. My approach for giving peer feedback is being as fair as possible, and I don't let the thought of it affecting the card game sway my decisions."_

For 15% of students, the game increased their awareness of feedback quality without fully changing their habits. One student shared, _"Knowing that you get more yellow cards definitely prompted me to give more in-depth peer feedback,"_ while another mentioned, _"I wouldn't go out of my way to provide feedback, but if it was an easy bug fix that I could provide, I would give them the feedback on it."_

A smaller group (10%) reported feeling pressured or confused about how the game tied into their feedback quality. One student expressed concern that _"After the card game, I felt that the bar for effort in grading was set from our previous results. It put pressure to either match how we graded previously or improve while discouraging doing any less than that."_ Another noted, _"Today was the first day that I played the card game, and honestly, I had no idea how it worked, so I never thought of the card game when I was grading before."_

These qualitative insights highlighted the varying degrees to which students internalized the intervention. Student responses varied, with some expressing strong motivation, others showing minimal change, and a few feeling pressure or confusion.

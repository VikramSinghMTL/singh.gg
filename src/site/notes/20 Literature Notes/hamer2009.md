---
{"title":"Quality of peer assessment in CS1","authors":["[[John Hamer]]","[[Helen C. Purchase]]","[[Paul Denny]]","[[Andrew Luxton-Reilly]]"],"date":"2009-08-10","processed":false,"tags":["computer-science","peer-assessment"],"dg-publish":true,"created":"2024-08-30","modified":"2024-09-13","permalink":"/20-literature-notes/hamer2009/","dgPassFrontmatter":true,"updated":"2024-09-13"}
---


> [!abstract]+
> While popularity of peer assessment in Computer Science has increased in recent years, the validity of peer assessed marks remain a signiﬁcant concern to instructors and source of anxiety to students. We report here on a large-scale study (1,500 students and 10,000 reviews) involving three introductory programming classes which recorded grades and feedback comments for both student and tutor reviews of novice programs. Using a paired analysis, we compare the quantitative marks given by students with those given by tutors, for both functional and non-functional aspects of the program. We also report on an analysis of the lexical sophistication of feedback comments.

> [!questions]+
>
> 1. • How competent are the student reviewers at making appropriate assessments of their peers’ assignments? • How sophisticated are the reviewers’ textual comments? ([@hamer2009, 2](zotero://open-pdf/library/items/SQSY37FN?page=2&annotation=UKCCQ5FR))

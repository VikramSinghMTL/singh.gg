---
{"title":"Is AI a Valid Source","creators":["[[Sharon Coyle]]"],"date":"2023-02-16","processed":true,"dg-publish":true,"tags":["ai","pedagogy","technology","video"],"url":"https://youtu.be/5rY7Skx4ozc","zotero":"zotero://select/library/items/CWWWKV8D","created":"2025-02-16","modified":"2025-02-16","permalink":"/20-literature-notes/coyle2023/","dgPassFrontmatter":true,"updated":"2025-02-16"}
---


> [!summary]+
> The webinar explores the impact of AI tools like ChatGPT on education, particularly their unreliability as sources and their ethical and pedagogical implications. AI-generated text is not based on factual retrieval but on probabilistic word prediction, leading to hallucinated sources and misinformation. The discussion emphasizes that blocking AI is not a sustainable solution, as students will continue to access it outside the classroom. Instead, educators must integrate AI literacy into teaching, helping students critically assess AI outputs and understand when AI-generated information is unreliable. Ethical concerns surrounding AI include bias in datasets, exploitation of human labor in training AI models, and the environmental costs of running AI systems. The webinar stresses that assessments need to evolve, shifting away from fact-recall tasks toward synthesis, analysis, and critical thinking assignments. While AI poses challenges, it can also be used as a tool for learning, aiding in brainstorming, structuring ideas, and revision processes—but only when combined with human oversight and source verification. The session concludes that clear policies on AI use in coursework should be established to provide students with transparent guidelines on responsible AI integration in education.

> [!insights]+
> - AI literacy needs to be explicitly taught—students (and even faculty) often assume AI works like a search engine when in reality, it hallucinates plausible-sounding but false information. This means source literacy must now extend to AI-generated content.
> - Assessments must evolve to outpace AI capabilities—fact-recall and summary-based assignments are increasingly obsolete. Instead, coursework should focus on contextualized critical thinking, synthesis across sources, and verification tasks where students must defend claims with proven evidence.
> - Pedagogical shifts should embrace AI, not resist it—rather than banning AI, it can be incorporated as a tool for brainstorming, generating counterarguments, and structuring ideas, as long as students remain accountable for accuracy and source validation.
> - Ethical AI use should be a classroom discussion—AI carries real-world ethical implications, from bias in training data to labor exploitation in dataset curation. Students should engage in discussions on what it means to use AI responsibly.
> - Prompt engineering is a skill worth developing—crafting precise AI queries directly impacts output quality. Teaching students how to refine AI-generated responses and recognize gaps in reasoning should be embedded into digital literacy education.
> - AI-generated feedback could supplement peer review—AI tools can already provide surface-level revision suggestions (grammar, structure, clarity). This could free up peer and instructor feedback to focus on higher-order concerns like argumentation, originality, and depth of analysis.

> [!cite]+
> Coyle, S. (2023, February 16). _Is AI a Valid Source_. SALTISE Webinar. [https://youtu.be/5rY7Skx4ozc](https://youtu.be/5rY7Skx4ozc)
